{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from random import choice\n",
    "import gym\n",
    "import pandas as pd\n",
    "import pygame\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from gym import spaces\n",
    "from copy import deepcopy\n",
    "import pygame.font\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.specs import array_spec\n",
    "pygame.font.init()\n",
    "pygame.init()\n",
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validwords = []\n",
    "with open('resources/wordlist.txt') as wordlist:\n",
    "    for line in wordlist:\n",
    "        # clean the line\n",
    "        text = line.replace('\\n', '')\n",
    "        validwords.append(text.lower().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wordle:\n",
    "    def __init__(self, word, rows=6, letters=5):\n",
    "        self.g_count = 0\n",
    "        self.word = word\n",
    "        self.w_hash_table = {}\n",
    "        if word is not None:\n",
    "            for x, l in enumerate(word):\n",
    "                if l in self.w_hash_table:\n",
    "                    self.w_hash_table[l]['count'] += 1\n",
    "                    self.w_hash_table[l]['pos'].append(x)\n",
    "                else:\n",
    "                    self.w_hash_table[l] = {'count':1, 'pos':[x]}\n",
    "        self.rows = rows\n",
    "        self.letters = letters\n",
    "        self.board = [['' for _ in range(letters)] for _ in range(rows)]\n",
    "        self.colours = [['B' for _ in range(letters)] for _ in range(rows)]\n",
    "        self.alph = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "\n",
    "    def is_end(self):\n",
    "        if self.board[-1] != ['' for _ in range(self.letters)]:\n",
    "            return True\n",
    "        else:\n",
    "            r = self.game_result()\n",
    "            if r[0] == True:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def game_result(self):\n",
    "        win = (False, 100)\n",
    "        for i, r in enumerate(self.board):\n",
    "            if self.word == ''.join(r):\n",
    "                win = (True, i)\n",
    "                break\n",
    "        return win\n",
    "\n",
    "    def update_board(self, u_inp):\n",
    "        w_hash_table = deepcopy(self.w_hash_table)\n",
    "        i_hash_table = {}\n",
    "        for x, l in enumerate(str(u_inp).upper()):\n",
    "            self.board[self.g_count][x] = l\n",
    "            if l in i_hash_table:\n",
    "                i_hash_table[l].append(x)\n",
    "            else:\n",
    "                i_hash_table[l] = [x]\n",
    "        colours = {'G':[],'B':[],'Y':[]}\n",
    "        for l in i_hash_table:\n",
    "            if l in w_hash_table:\n",
    "                g_hold = []\n",
    "                for p in i_hash_table[l]:\n",
    "                    if p in w_hash_table[l]['pos']:\n",
    "                        g_hold.append(p)\n",
    "                for p in g_hold:\n",
    "                    i_hash_table[l].remove(p)\n",
    "                colours['G'] += g_hold\n",
    "                if len(g_hold) < w_hash_table[l]['count']:\n",
    "                    y_hold = []\n",
    "                    for p in i_hash_table[l]:\n",
    "                        y_hold.append(p)\n",
    "                        if len(y_hold) == w_hash_table[l]['count']:\n",
    "                            break\n",
    "                    for p in y_hold:\n",
    "                        i_hash_table[l].remove(p)\n",
    "                    colours['Y'] += y_hold\n",
    "                for p in i_hash_table[l]:\n",
    "                    colours['B'].append(p)\n",
    "            else:\n",
    "                colours['B'] += i_hash_table[l]\n",
    "                i_hash_table[l] = []\n",
    "        for c in colours:\n",
    "            for p in colours[c]:\n",
    "                self.colours[self.g_count][p] = c\n",
    "        self.g_count += 1\n",
    "\n",
    "    def valid_guess(self, u_inp):\n",
    "        if len(u_inp) == 5 and False not in [False for s in str(u_inp).upper() if s not in self.alph]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "class WordleEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    SCREEN_DIM = 500\n",
    "    GREEN = \"#6aaa64\"\n",
    "    YELLOW = \"#c9b458\"\n",
    "    GREY = \"#787c7e\"\n",
    "    OUTLINE = \"#d3d6da\"\n",
    "    FILLED_OUTLINE = \"#878a8c\"\n",
    "\n",
    "    def __init__(self, answers, logging=False):\n",
    "        self.logging = logging\n",
    "        self.answers = pd.DataFrame(answers)\n",
    "        self.answers.columns = ['words']\n",
    "        self.screen = None\n",
    "        self.isopen = False\n",
    "        self.GUESSES = 6\n",
    "        self.LETTERS = 5\n",
    "        self.WORD = self.answers['words'].sample(n=1).tolist()[0].upper()\n",
    "        self.WORDLE = Wordle(self.WORD, self.GUESSES, self.LETTERS)\n",
    "        self.alpha = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "        self.colors = ['B', 'Y', 'G']\n",
    "        self.is_game_over = False\n",
    "        self.guessed_words = []\n",
    "        self.blank_letters = []\n",
    "\n",
    "        # our action space is the total amount of possible words to guess\n",
    "        self.action_space = spaces.Discrete(len(answers))\n",
    "        #our observation space is the current wordle board in form of (letter, color) with 5x6 (5 letters, 6 guesses)\n",
    "        #modified to work with gym/baselines\n",
    "        #same thing basically, only 0-26 is '' to z and 27-29 is B, Y, G\n",
    "        # first 6 rows are guesses and last 6 rows are colors\n",
    "        # changed shape to be 3 dimensions so that we can apply conv2d layers to it\n",
    "        # at some point we should try to normalize the obs space\n",
    "        # since right now its on a 0-29 scale instead of a 0-1.\n",
    "        self.observation_space = spaces.Box(low=0, high=29, shape=(1,1,12,5), dtype='int32')\n",
    "        self.current_episode = -1\n",
    "        self.episode_memory: list[any] = []\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.is_game_over:\n",
    "            return RuntimeError('Episode is already done')\n",
    "        self._take_action(action)\n",
    "        reward = self._get_reward()\n",
    "        observation = self._get_observation()\n",
    "        return observation, reward, self.is_game_over, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_episode = -1\n",
    "        self.episode_memory.append([])\n",
    "        self.is_game_over = False\n",
    "        self.WORD = self.answers['words'].sample(n=1).tolist()[0].upper()\n",
    "        self.WORDLE = Wordle(self.WORD, self.GUESSES, self.LETTERS)\n",
    "        self.guessed_words = []\n",
    "        self.blank_letters = []\n",
    "        if self.logging:\n",
    "            #print(self.WORDLE.word)\n",
    "            pass\n",
    "        self.close()\n",
    "        return self._get_observation()\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pygame.init()\n",
    "        pygame.display.init()\n",
    "        self.screen = pygame.display.set_mode((self.SCREEN_DIM, self.SCREEN_DIM))\n",
    "        font = pygame.font.Font('freesansbold.ttf', 30)\n",
    "        for col in range(0, 5):\n",
    "            for row in range(0, 6):\n",
    "                pygame.draw.rect(self.screen, self.OUTLINE, [col * 100 + 12, row * 100 + 12, 75, 75], 3, 5)\n",
    "                color = self.GREEN if self.WORDLE.colours[row][col] == 'G' else self.YELLOW if self.WORDLE.colours[row][col] == 'Y' else self.GREY\n",
    "                piece_text = font.render(self.WORDLE.board[row][col], True, color)\n",
    "                self.screen.blit(piece_text, (col * 100 + 30, row * 100 + 25))\n",
    "        #pygame.draw.rect(screen, self.GREEN, [5, turn * 100 + 5, WIDTH - 10, 90], 3, 5)\n",
    "        if mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            pygame.display.flip()             \n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        # turn action into guess\n",
    "        guess = self.answers['words'][action]\n",
    "        self.episode_memory[self.current_episode].append(guess)\n",
    "        self.guessed_words.append(guess)\n",
    "        if self.logging:\n",
    "            ##print(guess)\n",
    "            pass\n",
    "        self.WORDLE.update_board(guess)\n",
    "        res = self.WORDLE.colours[self.WORDLE.g_count-1]\n",
    "        self.blank_letters.extend([ l for i,l in enumerate(guess) if res[i] == 'B' and l not in self.blank_letters])\n",
    "        self.is_game_over = self.WORDLE.word == guess or self.WORDLE.g_count == self.GUESSES\n",
    "        \n",
    "        if self.is_game_over and self.logging:\n",
    "            print(f'Guessed in : {len(self.guessed_words)} \\nWords: ', end='')\n",
    "            print(*self.guessed_words, sep=\",\")\n",
    "            print(f'Answer: {self.WORD}')\n",
    "\n",
    "    def _get_reward(self):\n",
    "        result, tries = self.WORDLE.game_result()\n",
    "        rewards = np.zeros(5)\n",
    "        #heavily penealize guessing the same word multiple times\n",
    "        #If a word isn't the right guess, we shouldn't guess it again\n",
    "        #could do the same thing for letters, as if a letter is blank(grey)\n",
    "        # then the only reason to use a word with a letter in it\n",
    "        # is to check other letter posistions\n",
    "        #so it shouldn't be a heavy penalty but it should be a penalty\n",
    "        for i,c in enumerate(self.WORDLE.colours[self.WORDLE.g_count-1]):\n",
    "            if c == self.colors[2]:\n",
    "                rewards[i] = 2\n",
    "            elif c == self.colors[1]:\n",
    "                rewards[i] = 1\n",
    "        #check guesses up to and including our current guess\n",
    "        if self.logging:\n",
    "            #print(self.WORD)\n",
    "            #print(rewards)\n",
    "            pass\n",
    "        reward = np.mean(rewards)\n",
    "        for g in range(self.WORDLE.g_count):\n",
    "            word = self.WORDLE.board[g]\n",
    "            current = ''.join(word)\n",
    "            if current in self.guessed_words:\n",
    "                return 0\n",
    "            for l in word: \n",
    "                if l in self.blank_letters:\n",
    "                    reward -= 0.3\n",
    "        return reward\n",
    "\n",
    "    def _get_observation(self):\n",
    "        board = np.array(self.WORDLE.board) #2d array of 5x6\n",
    "        colors = np.array(self.WORDLE.colours) #2d array of 5x6\n",
    "        results = np.vstack((board, colors)) #stacks boards and colors by rows resulting in a 2d array of 5x12\n",
    "        convertletterstonum = lambda letter: [self.alpha.index(l) + 1 if l in self.alpha else 0 for l in letter]\n",
    "        convertcolortonum = lambda color: [self.colors.index(c)+27 for c in color]\n",
    "        guesses = np.array([convertletterstonum(l) if i <=5 else convertcolortonum(l) for i, l in enumerate(results)])\n",
    "        guesses3d = np.expand_dims(guesses, axis=0)\n",
    "        if self.logging:\n",
    "            pass\n",
    "            #print(np.shape(guesses))\n",
    "            #print(np.shape(guesses3d))\n",
    "        return guesses3d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 12, 5)\n",
      "2315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = WordleEnv(validwords)\n",
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "print(states)\n",
    "print(actions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=5000, target_model_update=1e-2)\n",
    "    return dqn\n",
    "\n",
    "def build_model(states, actions):\n",
    "    model = tf.keras.models.Sequential()    \n",
    "    model.add(tf.keras.layers.Input(states))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(actions, activation='linear'))\n",
    "    return model\n",
    "def create_q_model(states, actions):\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=states)\n",
    "    common = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "    action = layers.Dense(actions, activation=\"softmax\")(common)\n",
    "    critic = layers.Dense(1)(common)\n",
    "    # Convolutions on the frames on the screen\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=[actions, critic])\n",
    "\n",
    "adamopt = tf.keras.optimizers.legacy.Adam(learning_rate=0.01, name=\"adam\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 1, 1, 12, 128)     768       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1, 1, 12, 64)      8256      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1, 1, 12, 32)      2080      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2315)              891275    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 902,379\n",
      "Trainable params: 902,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training for 7 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "    7/10000 [..............................] - ETA: 19:40 - reward: 0.4286  done, took 1.554 seconds\n"
     ]
    }
   ],
   "source": [
    "adamopt = tf.keras.optimizers.legacy.Adam(learning_rate=0.3, name=\"adam\") # Not using legacy optimizer creates attribution error\n",
    "\n",
    "model = build_model(states, actions)\n",
    "DQN = build_agent(model, actions)\n",
    "model.summary()\n",
    "DQN.compile(optimizer=adamopt)\n",
    "try:\n",
    "    #DQN.load_weights('dqn_weights.h5f')\n",
    "    raise KeyError\n",
    "except:\n",
    "    history = DQN.fit(env, nb_steps=7, visualize=True, verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 1.000, steps: 6\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bobby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "scores = DQN.test(env, nb_episodes=1, visualize=True)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.display.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mepisode_reward\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['episode_reward'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN.save_weights('dqn_weights.h5f', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

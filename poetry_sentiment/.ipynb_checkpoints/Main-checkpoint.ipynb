{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16e04c0",
   "metadata": {},
   "source": [
    "Quick Note: As you can see I have all the imports done in the cell below. for some reason my notebook ocassionally hangs when importing from functions.py. Also, I found it removes the time by about half for the actual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b90611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from os import system, listdir\n",
    "from os.path import isfile, join\n",
    "from random import shuffle\n",
    "import csv\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import download\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from joblib import dump, load # used for saving and loading sklearn objects\n",
    "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from random import randint\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from scipy.sparse import csr_matrix\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279d21f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted data from poem-sentiment/data\\dev.tsv\n",
      "extracted data from poem-sentiment/data\\test.tsv\n",
      "extracted data from poem-sentiment/data\\train.tsv\n"
     ]
    }
   ],
   "source": [
    "#make csv files of the poetry data sets\n",
    "poetry_sets = data_framify('poem-sentiment/data', [1, 2])\n",
    "paths = ['csv/poetry-dev.csv', 'csv/poetry-test.csv', 'csv/poetry-train.csv']\n",
    "\n",
    "poetry_sets[0].to_csv(paths[0])\n",
    "poetry_sets[1].to_csv(paths[1])\n",
    "poetry_sets[2].to_csv(paths[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97469153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts\n",
      "SGD Train score: 1.0 ; Validation score: 0.52\n",
      "SVM Train score : 1.0 ; SVM Validation score : 0.52\n",
      "Naives Bayes Train Score: 0.84 ; Naive Bayes Validation score: 0.55\n",
      "\n",
      "Unigram Tf-Idf\n",
      "SGD Train score: 1.0 ; Validation score: 0.51\n",
      "SVM Train score : 0.79 ; SVM Validation score : 0.62\n",
      "Naives Bayes Train Score: 0.63 ; Naive Bayes Validation score: 0.62\n",
      "\n",
      "Bigram Counts\n",
      "SGD Train score: 1.0 ; Validation score: 0.59\n",
      "SVM Train score : 1.0 ; SVM Validation score : 0.58\n",
      "Naives Bayes Train Score: 0.99 ; Naive Bayes Validation score: 0.46\n",
      "\n",
      "Bigram Tf-Idf\n",
      "SGD Train score: 1.0 ; Validation score: 0.61\n",
      "SVM Train score : 0.96 ; SVM Validation score : 0.62\n",
      "Naives Bayes Train Score: 0.62 ; Naive Bayes Validation score: 0.62\n",
      "\n",
      "Trigram Counts\n",
      "SGD Train score: 1.0 ; Validation score: 0.6\n",
      "SVM Train score : 1.0 ; SVM Validation score : 0.61\n",
      "Naives Bayes Train Score: 1.0 ; Naive Bayes Validation score: 0.43\n",
      "\n",
      "Trigram Tf-Idf\n",
      "SGD Train score: 1.0 ; Validation score: 0.61\n",
      "SVM Train score : 0.99 ; SVM Validation score : 0.62\n",
      "Naives Bayes Train Score: 0.62 ; Naive Bayes Validation score: 0.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now, begin to learn about the data\n",
    "poetry_train = poetry_sets[2]\n",
    "path = 'skobjects/'\n",
    "train_list = vectorize_data(poetry_train, path)\n",
    "XTU, XTUT, XTB, XTBT, XTT, XTTT = train_list[0:]\n",
    "learn(XTU, XTUT, XTB, XTBT, XTT, XTTT, poetry_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff5947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = poetry_train['label'].values\n",
    "#uni_RF = RandomForestModel(XTUT, y, 'Unigram tf-idf')\n",
    "#bi_rf = RandomForestModel(XTBT, y, 'Bigram tf-idf')\n",
    "#tri_tf = RandomForestModel(XTTT, y, 'Trigram tf-idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3eff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, use the best data form to learn optimal things\n",
    "#best_learn(XTTT, poetry_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1336fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m XTU_seq \u001b[38;5;241m=\u001b[39m \u001b[43mseq_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXTU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnigram\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m XTB_seq \u001b[38;5;241m=\u001b[39m seq_neural_network(XTB, y, [\u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m41\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBigram\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m XTT_seq \u001b[38;5;241m=\u001b[39m seq_neural_network(XTT, y, [\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m85\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrigram\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Coding\\poetry_math\\functions.py:369\u001b[0m, in \u001b[0;36mseq_neural_network\u001b[1;34m(X, y, units, type)\u001b[0m\n\u001b[0;32m    367\u001b[0m X_train \u001b[38;5;241m=\u001b[39m convert_to_tensor(csr_matrix\u001b[38;5;241m.\u001b[39mtoarray(X_train))\n\u001b[0;32m    368\u001b[0m X_valid \u001b[38;5;241m=\u001b[39m convert_to_tensor(csr_matrix\u001b[38;5;241m.\u001b[39mtoarray(X_valid))\n\u001b[1;32m--> 369\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m X_valid \u001b[38;5;241m=\u001b[39m reshape(X_valid, [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m32\u001b[39m, X_valid\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m#Open Sequentional model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "XTU_seq = seq_neural_network(XTU, y, [15, 26, 32], 'Unigram')\n",
    "XTB_seq = seq_neural_network(XTB, y, [13, 28, 41], 'Bigram')\n",
    "XTT_seq = seq_neural_network(XTT, y, [16, 3, 85], 'Trigram')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTU_seq.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67560138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
